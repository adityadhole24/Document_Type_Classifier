# -*- coding: utf-8 -*-
"""DMWMiniProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17WVLhCzVQdHfMx7Dyac632lR99OHED7B
"""

import os
import pandas as pd
import numpy as np
from google.colab import files
import io
import nltk
import seaborn as sns
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from nltk.stem.wordnet import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_selection import chi2
from sklearn.manifold import TSNE
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from IPython.display import display


nltk.download('stopwords')
nltk.download('wordnet')

#Reading the dataset and encoding the category as another attribute
df = pd.read_csv('/content/bbc-text.csv')
df.head()
df['category_id'] = df['category'].factorize()[0]

category_id_df = df[['category', 'category_id']].drop_duplicates().sort_values('category_id')
category_to_id = dict(category_id_df.values)
id_to_category = dict(category_id_df[['category_id', 'category']].values)

df.head()

print(df['text'][2])

#Data-Preprocessing - removing stopwords, stemming/lemmatization
#Using Snowball Stemmer instead of Porter, because of better results

df.sample(n=10)
df.sample(n=10)
stop_words= set(stopwords.words('english'))
stemmer = SnowballStemmer("english")
lemmatizer = WordNetLemmatizer()

for ind in df.index:
  filtered=[]
  for w in df['text'][ind].split():
    if w not in stop_words:
       filtered.append(lemmatizer.lemmatize(w.lower()))
  result = ' '.join(filtered) 
  df['text'][ind] = result

df.sample(n=20,random_state=0)

df.groupby('category').category_id.count().plot.bar(ylim=0)

#Representing each of the 2225 documents by a feature vector
#Technique used for the purpose is TF-IDF

tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1',ngram_range=(1,2))
features = tfidf.fit_transform(df.text).toarray()   #toarray # 2225 * 17512
labels=df.category_id
features.shape
print(features)



# Corelation analysis

N = 3
for category, category_id in sorted(category_to_id.items()):
  features_chi2 = chi2(features, labels == category_id)
  indices = np.argsort(features_chi2[0])
  feature_names = np.array(tfidf.get_feature_names())[indices]
  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]
  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]
  print("# '{}':".format(category))
  print("  . Most correlated unigrams:\n       . {}".format('\n       . '.join(unigrams[-N:])))
  print("  . Most correlated bigrams:\n       . {}".format('\n       . '.join(bigrams[-N:])))

# Sampling a subset(30%) of our dataset because t-SNE is computationally expensive
SAMPLE_SIZE = int(len(features) * 0.3)
np.random.seed(0)
indices = np.random.choice(range(len(features)), size=SAMPLE_SIZE, replace=False) # 667
projected_features = TSNE(n_components=2, random_state=0).fit_transform(features[indices]) # 667*2
colors = ['pink', 'green', 'midnightblue', 'orange', 'darkgrey']
for category, category_id in sorted(category_to_id.items()):
    points = projected_features[(labels[indices] == category_id).values]
    plt.scatter(points[:, 0], points[:, 1], s=30, c=colors[category_id], label=category)
plt.title("tf-idf feature vector for each article, projected on 2 dimensions.",
          fontdict=dict(fontsize=15))
plt.legend()

projected_features.shape

features.shape

# 5-fold Cross Validation for all the models and print results model wise
models = [
    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),
    MultinomialNB(),
    LogisticRegression(random_state=0),
]
CV = 5
cv_df = pd.DataFrame(index=range(CV * len(models)))
entries = []


for model in models:
  model_name = model.__class__.__name__
  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)
  for fold_idx, accuracy in enumerate(accuracies):
    entries.append((model_name, fold_idx, accuracy))
cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])
cv_df

cv_df.groupby('model_name').accuracy.mean()

sns.boxplot(x='model_name', y='accuracy', data=cv_df)
#sns.stripplot(x='model_name', y='accuracy', data=cv_df, 
 #             size=8, jitter=True, edgecolor="gray", linewidth=2)

X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(features, labels, df.index, test_size=0.33, random_state=0)

model1=RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)
model2= MultinomialNB()
model3= LogisticRegression(random_state=0)

model1.fit(X_train,y_train)
model2.fit(X_train,y_train)
model3.fit(X_train,y_train)


y_pred1=model1.predict(X_test)
y_pred2=model2.predict(X_test)
y_pred3=model3.predict(X_test)


conf_matrix= confusion_matrix(y_test,y_pred1)
sns.heatmap(conf_matrix, annot=True, fmt='d',
            xticklabels=category_id_df.category.values, yticklabels=category_id_df.category.values)
plt.ylabel('Actual')
plt.xlabel('Predicted')

print('Confusion Matrix when predicted using Random Forest Classifier')

print(classification_report(y_test,y_pred1, target_names=['Tech','business','Sport','Entertainment','Politics']))

conf_matrix= confusion_matrix(y_test,y_pred2)
sns.heatmap(conf_matrix, annot=True, fmt='d',
            xticklabels=category_id_df.category.values, yticklabels=category_id_df.category.values)
plt.ylabel('Actual')
plt.xlabel('Predicted')
print('Confusion Matrix when classified using Multionomial Naive Bayes Classifier')

print(classification_report(y_test,y_pred2, target_names=['Tech','business','Sport','Entertainment','Politics']))

conf_matrix= confusion_matrix(y_test,y_pred3)
sns.heatmap(conf_matrix, annot=True, fmt='d',
            xticklabels=category_id_df.category.values, yticklabels=category_id_df.category.values)
plt.ylabel('Actual')
plt.xlabel('Predicted')
print('Confusion Matrix when classfied using Logistic Regression')

print(classification_report(y_test,y_pred3, target_names=['Tech','business','Sport','Entertainment','Politics']))

accuracies = []
accuracies.append(accuracy_score(y_test,y_pred1)*100)
accuracies.append(accuracy_score(y_test,y_pred2)*100)
accuracies.append(accuracy_score(y_test,y_pred3)*100)
print(accuracies)

labels= ['Random Forest','Multinomial NB','Logistic Regression']

index = np.arange(len(labels))
plt.figure(figsize=(8,8))
plt.bar(index,accuracies)
plt.xlabel('Classifier',fontsize=15)
plt.ylabel('Accuracy Score',fontsize=15)
plt.xticks(index,labels,fontsize=15,rotation=30)
plt.title('Accuracy Score Comparison of the 3 classifiers',fontsize=15)

plt.show()

#Print the incorrectly predicted documents
for predicted in category_id_df.category_id:
  for actual in category_id_df.category_id:
    if predicted != actual and conf_matrix[actual, predicted] >= 2:
      print("'{}' predicted as '{}' : {} examples.".format(id_to_category[actual], id_to_category[predicted], conf_matrix[actual, predicted]))
      display(df.loc[indices_test[(y_test == actual) & (y_pred1 == predicted)]][['text','category']])
      print('')